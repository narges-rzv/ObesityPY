{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pediatric Obesity Prediction\n",
    "\n",
    "### 13 April 2018\n",
    "### Rob Hammond\n",
    "\n",
    "This notebook acts as both a demonstration of how to use the ObesityPY package as well as the final results of the modeling for the Comprehensive Program on Obesity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import train\n",
    "import build_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data\n",
    "d1 = pickle.load(open('../python objects/patientdata_20170823.pkl', 'rb'))\n",
    "d1mom = pickle.load(open('../python objects/patient_mother_data_20170724.pkl', 'rb'))\n",
    "lat_lon_dic = pickle.load(open('../python objects/lat_lon_data_20180329.pkl', 'rb'))\n",
    "env_dic= pickle.load(open('../python objects/census_data_20170920.pkl', 'rb'))\n",
    "d1mom_hist = pickle.load(open('../python objects/full_lutheran_mother_data.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables for predicting using data from 0 to 24 months to predict at 4.5 to 5.5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "newdir='../outputs_age_analyses'+timestr\n",
    "if not os.path.isdir(newdir):\n",
    "    os.mkdir(newdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agex_low = 4.5\n",
    "agex_high = 5.5\n",
    "months_from = 0\n",
    "months_to = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data base level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 52,945 patients: 52945it [03:56, 223.79it/s]   \n"
     ]
    }
   ],
   "source": [
    "x1,y1,y1label,feature_headers,mrns = build_features.call_build_function(d1, d1mom, d1mom_hist, lat_lon_dic, env_dic, agex_low, agex_high, months_from, months_to, False, prediction='multi')\n",
    "\n",
    "np.savez_compressed(newdir+'/raw_matrix_data_'+str(months_to)+'months', x=x1, y=y1, ylabel=y1label, mrns=mrns, features=np.array(feature_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of underweight children: 257\n",
      "Number of normal children: 6,924\n",
      "Number of overweight children: 2,035\n",
      "Number of obese children: 2,278\n",
      "Number of class I severe obesity children: 375\n",
      "Number of class II severe obesity children: 98\n"
     ]
    }
   ],
   "source": [
    "label_ix = {'underweight':0,'normal':1,'overweight':2,'obese':3,'class I severe obesity':4,'class II severe obesity':5}\n",
    "for label, ix in label_ix.items():\n",
    "    print('Number of {0:s} children: {1:,d}'.format(label,int(y1label[:,ix].sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get modeling subset and split into boys and girls data sets for predicting the Obese label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_wt_bmi = [fh for fh in feature_headers if not any([x in fh for x in ('Wt','BMI')])]\n",
    "no_census = [fh for fh in feature_headers if not any([x in fh.lower() for x in ('census','zipcode')])]\n",
    "\n",
    "data = {'boys':{\n",
    "    'no_min':{\n",
    "        'full':{'data':[], 'variablesubset':[]},\n",
    "        'no_census':{'data':[], 'variablesubset':no_census, 'filt_str':['Gender:0']},\n",
    "        'no_wt_bmi':{'data':[], 'variablesubset':no_wt_bmi, 'filt_str':['Gender:0']},\n",
    "        'wfl_latest':{'data':[], 'variablesubset':no_wt_bmi, 'filt_str':['Gender:0']},\n",
    "        'wfl_19_24':{'data':[], 'variablesubset':[], 'filt_str':['Gender:0','Vital: Wt for Length ZScore-avg19to24']},\n",
    "        'wfl_latest':{'data':[], 'variablesubset':[], 'filt_str':['Gender:0', 'Vital: Wt for Length ZScore-avg19to24']},\n",
    "        'bmi_19_24':{'data':[], 'variablesubset':[], 'filt_str':['Gender:0','Vital: BMI-avg19to24']},\n",
    "        'bmi_latest':{'data':[], 'variablesubset':[], 'filt_str':['Gender:0', 'Vital: BMI-latest']}\n",
    "        },\n",
    "    'min_5':{\n",
    "        'full':{'data':[], 'variablesubset':[], 'filt_str':['Gender:0']},\n",
    "        'no_census':{'data':[], 'variablesubset':no_census, 'filt_str':['Gender:0']},\n",
    "        'no_wt_bmi':{'data':[], 'variablesubset':no_wt_bmi, 'filt_str':['Gender:0']}\n",
    "        },\n",
    "    'lasso_fts':{\n",
    "        'full':{'data':[], 'variablesubset':[]}, 'filt_str':['Gender:0'],\n",
    "        'no_census':{'data':[], 'variablesubset':no_census, 'filt_str':['Gender:0']},\n",
    "        'no_wt_bmi':{'data':[], 'variablesubset':no_wt_bmi, 'filt_str':['Gender:0']}\n",
    "        },\n",
    "    },\n",
    "    'girls':{\n",
    "        'no_min':{\n",
    "            'full':{'data':[], 'variablesubset':[], 'filt_str':['Gender:1']},\n",
    "            'no_census':{'data':[], 'variablesubset':no_census, 'filt_str':['Gender:1']},\n",
    "            'no_wt_bmi':{'data':[], 'variablesubset':no_wt_bmi, 'filt_str':['Gender:1']},\n",
    "            'wfl_19_24':{'data':[], 'variablesubset':[], 'filt_str':['Gender:1','Vital: Wt for Length ZScore-avg19to24']},\n",
    "            'wfl_latest':{'data':[], 'variablesubset':[], 'filt_str':['Gender:1', 'Vital: Wt for Length ZScore-avg19to24']},\n",
    "            'bmi_19_24':{'data':[], 'variablesubset':[], 'filt_str':['Gender:1','Vital: BMI-avg19to24']},\n",
    "            'bmi_latest':{'data':[], 'variablesubset':[], 'filt_str':['Gender:1', 'Vital: BMI-latest']}\n",
    "            },\n",
    "        'min_5':{\n",
    "            'full':{'data':[], 'variablesubset':[], 'filt_str':['Gender:1'],\n",
    "            'no_census':{'data':[], 'variablesubset':no_census, 'filt_str':['Gender:1']},\n",
    "            'no_wt_bmi':{'data':[], 'variablesubset':no_wt_bmi, 'filt_str':['Gender:1']}\n",
    "            },\n",
    "        'lasso_fts':{\n",
    "            'full':{'data':[], 'variablesubset':[], 'filt_str':['Gender:1']},\n",
    "            'no_census':{'data':[], 'variablesubset':no_census, 'filt_str':['Gender:1']},\n",
    "            'no_wt_bmi':{'data':[], 'variablesubset':no_wt_bmi, 'filt_str':['Gender:1']}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-prepared data\n",
      "\n",
      "Original cohort size is: 52945 num features: 19290\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "startswith first arg must be str or a tuple of str, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-66d3f37e38fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mfeature_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdelay_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     lasso_selection=lasso_sel)\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mcorr_headers_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_headers_filtered\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_headers_filtered\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcorr_headers_filtered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mix_corr_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix_corr_headers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix_corr_headers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mix_corr_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/CPO/ObesityPY/src/train.py\u001b[0m in \u001b[0;36mprepare_data_for_analysis\u001b[0;34m(data_dic, data_dic_mom, data_dic_hist_moms, lat_lon_dic, env_dic, x1, y1, y1label, feature_headers, mrns, agex_low, agex_high, months_from, months_to, outcome, percentile, filterSTR, filterSTRThresh, variablesubset, variable_exclude, num_clusters, num_iters, dist_type, corr_vars_exclude, do_impute, mrnForFilter, add_time, bin_ix, do_normalize, min_occur, lasso_selection, binarize_diagnosis, get_char_tables, feature_info, subset, delay_print)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mreporting\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprint_statements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mix_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_training_set_forLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterSTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterSTRThresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdelay_print\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mget_char_tables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mprint_charac_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/CPO/ObesityPY/src/train.py\u001b[0m in \u001b[0;36mfilter_training_set_forLinear\u001b[0;34m(x, y, ylabel, headers, filterSTR, percentile, mrns, filterSTRThresh, print_out)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilterSTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# print(index_finder_filterstr + np.array([h.startswith(fstr) for h in headers]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mindex_finder_filterstr_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex_finder_filterstr_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/CPO/ObesityPY/src/train.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilterSTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# print(index_finder_filterstr + np.array([h.startswith(fstr) for h in headers]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mindex_finder_filterstr_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex_finder_filterstr_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: startswith first arg must be str or a tuple of str, not dict"
     ]
    }
   ],
   "source": [
    "for gender in [*data]:\n",
    "    for subset in [*data[gender]]:\n",
    "        min_occ = 5 if subset == 'min_5' else 0\n",
    "        lasso_sel = True if subset == 'lasso_fts' else False\n",
    "        for filt in [*data[gender][subset]]:\n",
    "            x2, y2, y2label, mrns2, ix_filter, feature_headers2, corr_headers_filtered, corrs_matrix_filterd, ix_corr_headers = \\\n",
    "                train.prepare_data_for_analysis({}, {}, {}, {}, {},\n",
    "                    x1, y1, y1label[:,label_ix['obese']], feature_headers, mrns,\n",
    "                    agex_low, agex_high, months_from, months_to,\n",
    "                    filterSTR=data[gender][subset][filt],\n",
    "                    variablesubset=data[gender][subset][filt]['variablesubset'],\n",
    "                    do_impute=False,\n",
    "                    do_normalize=True,\n",
    "                    min_occur=min_occ,\n",
    "                    feature_info=False,\n",
    "                    delay_print=False,\n",
    "                    lasso_selection=lasso_sel)\n",
    "        corr_headers_filtered = np.array(corr_headers_filtered) if type(corr_headers_filtered) == list else corr_headers_filtered\n",
    "        ix_corr_headers = np.array(ix_corr_headers) if type(ix_corr_headers) == list else ix_corr_headers\n",
    "        data[gender][subset][filt][data] = [x2, y2, y2label, mrns2, ix_filter, feature_headers2, corr_headers_filtered, corrs_matrix_filterd, ix_corr_headers]\n",
    "        np.savez_compressed(newdir+'/'+'_'.join(['x2',gender,months_to,'months_obese',subset,filt]), x2=x2, mrns2=mrns2, features2=np.array(feature_headers2), y2=y2, y2label=y2label, corr_mat=corrs_matrix_filterd, ix_corr_headers=ix_corr_headers, corr_headers_filtered=corr_headers_filtered)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_list = []\n",
    "auc_list = []\n",
    "r2_list = []\n",
    "exp_var_list = []\n",
    "prec_list = []\n",
    "results_list = []\n",
    "features_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gender in [*data]:\n",
    "    for subset in [*data[gender]]:\n",
    "        for filt in [*data[gender][subset]]:\n",
    "            x2, y2, y2label, mrns2, ix_filter, feature_headers2, corr_headers_filtered, corrs_matrix_filterd, ix_corr_headers = data[gender][subset][filt]['data']\n",
    "            for model_type in ('lasso','randomforest','gradientboost'):\n",
    "                title = ' '.join([gender.title(),'-',model_type.title(),subset,filt,'@'+str(months_to), 'obese'])\n",
    "                (model_list, randix_track, ix_train_track, ix_val_track, test_ix, results_arr, results_cols,\n",
    "                 feature_data, feature_data_cols, auc_val_mean, auc_val_mean_ste, var_val_mean, var_val_mean_ste, r2val_mean, r2val_mean_ste,\n",
    "                 auc_test_mean, auc_test_mean_ste, var_test_mean, var_test_mean_ste, r2test_mean, r2test_ste) = \\\n",
    "                        train.train_regression_model_for_bmi_parallel(x2, y2_no, y2label, feature_headers2, mrns2,\n",
    "                            corr_headers_filtered, corr_matrix_filtered, ix_corr_headers,\n",
    "                            modelType=model_type,\n",
    "                            percentile=False,\n",
    "                            return_data_for_error_analysis=False,\n",
    "                            feature_info=True)\n",
    "\n",
    "                title_list.append(title)\n",
    "                auc_list.append([auc_val_mean, auc_val_mean_ste, auc_test_mean, auc_test_mean_ste])\n",
    "                r2_list.append([r2val_mean, r2val_mean_ste, r2test_mean, r2test_mean_ste])\n",
    "                exp_var_list.append([exp_var_val_mean, exp_var_val_mean_ste, exp_var_test_mean, exp_var_test_mean_ste])\n",
    "                results_list.append(results_arr)\n",
    "                features_list.append(feature_data)\n",
    "                fname = '_'.join(['/'+gender,str(months_to),'months_obese',model_type,'index',subset,filt])\n",
    "                np.savez_compressed(newdir+fname, cv_ix=randix_track, train_ix=ix_train_track, val_ix=ix_val_track, test_ix=test_ix)\n",
    "                fname = '_'.join(['/'+gender,str(months_to),'months_obese',model_type,'results',subset,filt])\n",
    "                np.savez_compressed(newdir+fname, results=results_arr, results_cols=results_cols, features=feature_data, feature_cols=feature_data_cols)\n",
    "                fname = '_'.join(['/'+gender,str(months_to),'months_obese',model_type,'models',subset,filt])\n",
    "                pickle.dump(model_list, open(newdir+fname, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(titles_list, open(newdir+'/titles_list_'+str(months_to)+'_months_obese.pkl', 'wb'))\n",
    "pickle.dump(prec_list, open(newdir+'/prec_total_'+str(months_to)+'_months_obese.pkl', 'wb'))\n",
    "pickle.dump(recall_total, open(newdir+'/recall_total_'+str(months_to)+'_months_obese.pkl', 'wb'))\n",
    "pickle.dump(spec_total, open(newdir+'/spec_total_'+str(months_to)+'_months_obese.pkl', 'wb'))\n",
    "pickle.dump(auc_list, open(newdir+'/auc_list_'+str(months_to)+'_months_obese.pkl', 'wb'))\n",
    "pickle.dump(r2_list, open(newdir+'/r2_list_'+str(months_to)+'_months_obese.pkl', 'wb'))\n",
    "pickle.dump(results_list, open(newdir+'/results_list'+str(months_to)+'_months_obese.pkl', 'wb'))\n",
    "pickle.dump(features_list, open(newdir+'/features_list'+str(months_to)+'_months_obese.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
