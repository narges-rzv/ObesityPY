{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Data\n",
    "\n",
    "### This notebook serves as demonstration of how our data is created and provides an overview of what kind of information is available in each feature in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "import build_features\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib as imp\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 20000\n",
    "pd.options.display.width = 20000\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pickle.load(open('../python objects/patientdata_20170823.pkl', 'rb'))\n",
    "d1mom = pickle.load(open('../python objects/patient_mother_data_20170724.pkl', 'rb'))\n",
    "lat_lon_dic = pickle.load(open('../python objects/lat_lon_data_20180329.pkl', 'rb'))\n",
    "env_dic= pickle.load(open('../python objects/census_data_20170920.pkl', 'rb'))\n",
    "d1mom_hist = pickle.load(open('../python objects/full_lutheran_mother_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the data creation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agex_low = 4.5\n",
    "agex_high = 5.5\n",
    "months_from = 0\n",
    "months_to = 24\n",
    "\n",
    "label_ix = {'underweight':0,'normal':1,'overweight':2,'obese':3,'class I severe obesity':4,'class II severe obesity':5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the data from a nested dictionary format to a user-friendly matrix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 52,945 patients: 33268it [01:33, 357.03it/s]   "
     ]
    }
   ],
   "source": [
    "x1,y1,y1label,feature_headers,mrns = build_features.call_build_function(d1, d1mom, d1mom_hist, lat_lon_dic, env_dic, agex_low, agex_high, months_from, months_to, False, prediction='multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of patients: {0:,d}'.format(int(x1.shape[0])))\n",
    "print('Number of features: {0:,d}'.format(int(x1.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of children in cohort: {0:,d}'.format(int(y1.shape[0])))\n",
    "print('Total number of eligible children at age 5 (4.5-5.5): {0:,d}'.format(int(y1label.sum())))\n",
    "print('Total number of ineligible children at age 5 (4.5-5.5): {0:,d}'.format(int(y1.shape[0] - y1label.sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the number of features by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_info = []\n",
    "ft_cats = {}\n",
    "\n",
    "for f in feature_headers:\n",
    "    try:\n",
    "        ft_cats[f.split(':')[0]] += 1\n",
    "    except:\n",
    "        ft_cats[f.split(':')[0]] = 1\n",
    "        \n",
    "xsum = x1.sum(axis=0)\n",
    "for k in ft_cats:\n",
    "    cols = [f.startswith(k) for f in feature_headers]\n",
    "    ft_info.append([k, ft_cats[k], (xsum[cols] > 0).sum(), (xsum[cols] >= 5).sum()])\n",
    "\n",
    "ft_info = pd.DataFrame(ft_info, columns=['Feature Category', 'Number of Features', 'Number of Features with >0 Occurrences', 'Number of Features with >=5 Occurrences'])\n",
    "ft_info.to_csv('../summary_statistics/feature_categories.csv', index=False)\n",
    "ft_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the amount of information available in each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_info[['Number of Features','Number of Features with >0 Occurrences','Number of Features with >=5 Occurrences']].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum = (x1 > 0).sum(axis=0)\n",
    "for f, s in zip(feature_headers, xsum):\n",
    "    print('{0:s} has {1:,d} occurrences'.format(f,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average number of occurrences per feature {0:4.2f} with standard deviation: {1:4.2f}'.format(np.mean(xsum), np.std(xsum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the valid study cohort and output the relevant information for each feature if there are at least 5 occurrences in the data\n",
    "\n",
    "**NOTE: in this step there will be less features with at least 5 occurrences because we are also filtering rows that do not have maternal data or do not have a valid BMI reading (10 > BMI < 40) in the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, y2, y2label, mrns2, ix_filter, feature_headers2, corr_headers_filtered, corrs_matrix_filtered, ix_corr_headers = \\\n",
    "    train.prepare_data_for_analysis({}, {}, {}, {}, {},\n",
    "        x1, y1, y1label[:,label_ix['obese']], feature_headers, mrns,\n",
    "        agex_low, agex_high, months_from, months_to,\n",
    "        filterSTR=[], # use both boys and girls\n",
    "        variablesubset=[], # do not remove any features\n",
    "        do_impute=False, # do not impute values\n",
    "        do_normalize=False, # do not normalize the values\n",
    "        min_occur=5, # use only features with meaningful information\n",
    "        delay_print=False, # print out all information as it's available\n",
    "        lasso_selection=False # do not use LASSO feature selection\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_table = []\n",
    "cols = ['Variable', 'Total N', 'Total Average', 'Total Std Dev', 'Obese N', 'Obese Average', 'Obese Std Dev', 'Not Obese N', 'Not Obese Average', 'Not Obese Std Dev', 'Unadjusted Odds Ratio', 'Unadjusted OR Low', 'Unadjusted OR High', 'Relative Risk', 'p-value for OR']\n",
    "y2pos_ix = (y2label > 0)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    for ix, h in enumerate(feature_headers2):\n",
    "        bin_indicator = x2[:,ix].max()==1 and x2[:,ix].min()==0\n",
    "\n",
    "        ix_total = (x2[:,ix] != 0)\n",
    "        ix_total_pos = (y2label > 0) & (x2[:,ix] != 0)\n",
    "        ix_total_neg = (y2label == 0) & (x2[:,ix] != 0)\n",
    "\n",
    "        De = sum((y2label > 0) & (x2[:,ix] != 0)) * 1.0\n",
    "        He = sum((y2label == 0) & (x2[:,ix] != 0)) * 1.0\n",
    "        Dn = sum((y2label > 0) & (x2[:,ix] == 0)) * 1.0\n",
    "        Hn = sum((y2label == 0) & (x2[:,ix] == 0)) * 1.0\n",
    "\n",
    "        OR = (De/He)/(Dn/Hn)\n",
    "        OR_sterror = np.sqrt(1/De + 1/He + 1/Dn + 1/Hn)\n",
    "        OR_low, OR_high = np.exp(np.log(OR) - 1.96*OR_sterror), np.exp(np.log(OR) + 1.96*OR_sterror)\n",
    "\n",
    "        RR = (De/(De+He))/(Dn/(Dn+Hn))\n",
    "\n",
    "        md = x2[ix_total_pos,:][:,ix].mean() - x2[ix_total_neg,:][:,ix].mean()\n",
    "        se = np.sqrt( np.var(x2[ix_total_pos,:][:,ix]) / len(x2[ix_total_pos,:][:,ix]) + np.var(x2[ix_total_neg,:][:,ix])/len(x2[ix_total_neg,:][:,ix]))\n",
    "        lcl, ucl = md-2*se, md+2*se\n",
    "        z = md/se\n",
    "\n",
    "        pvalue = 2 * norm.cdf(-1*(np.abs(np.log(OR))/OR_sterror)) if bin_indicator else 2 * norm.cdf(-np.abs(z))\n",
    "        char_table.append([\n",
    "                h, ix_total.sum(), x2[ix_total,:][:,ix].mean(), x2[ix_total,:][:,ix].std(),\n",
    "                ix_total_pos.sum(), x2[ix_total_pos,:][:,ix].mean() if not(bin_indicator) else 0, x2[ix_total_pos,:][:,ix].std() if not(bin_indicator) else 0,\n",
    "                ix_total_neg.sum(), x2[ix_total_neg,:][:,ix].mean() if not(bin_indicator) else 0,  x2[ix_total_neg,:][:,ix].std() if not(bin_indicator) else 0,\n",
    "                OR if bin_indicator else 0, OR_low if bin_indicator else 0, OR_high if bin_indicator else 0, RR if bin_indicator else 0, pvalue\n",
    "        ])\n",
    "\n",
    "ft_info = pd.DataFrame(char_table, columns=cols)\n",
    "ft_info.to_csv('../summary_statistics/cohort_feature_summary_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ft_info.sort_values(by='Variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the boys subset of the data and output relevant information for each feature that has at least 5 occurrences in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_boys, y2_boys, y2label_boys, mrns2_boys, ix_filter_boys, feature_headers2_boys, corr_headers_filtered_boys, corrs_matrix_filtered_boys, ix_corr_headers_boys = \\\n",
    "    train.prepare_data_for_analysis({}, {}, {}, {}, {},\n",
    "        x1, y1, y1label[:,label_ix['obese']], feature_headers, mrns,\n",
    "        agex_low, agex_high, months_from, months_to,\n",
    "        filterSTR=['Gender:0'], # only the boys data\n",
    "        variablesubset=[], # do not remove any features\n",
    "        do_impute=False, # do not impute values\n",
    "        do_normalize=False, # do not normalize the values\n",
    "        min_occur=5, # use only features with meaningful information\n",
    "        delay_print=False, # print out all information as it's available\n",
    "        lasso_selection=False # do not use LASSO feature selection\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_table = []\n",
    "cols = ['Variable', 'Total N', 'Total Average', 'Total Std Dev', 'Obese N', 'Obese Average', 'Obese Std Dev', 'Not Obese N', 'Not Obese Average', 'Not Obese Std Dev', 'Unadjusted Odds Ratio', 'Unadjusted OR Low', 'Unadjusted OR High', 'Relative Risk', 'p-value for OR']\n",
    "y2pos_ix = (y2label_boys > 0)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    for ix, h in enumerate(feature_headers2_boys):\n",
    "        bin_indicator = x2_boys[:,ix].max()==1 and x2_boys[:,ix].min()==0\n",
    "\n",
    "        ix_total = (x2_boys[:,ix] != 0)\n",
    "        ix_total_pos = (y2label_boys > 0) & (x2_boys[:,ix] != 0)\n",
    "        ix_total_neg = (y2label_boys == 0) & (x2_boys[:,ix] != 0)\n",
    "\n",
    "        De = sum((y2label_boys > 0) & (x2_boys[:,ix] != 0)) * 1.0\n",
    "        He = sum((y2label_boys == 0) & (x2_boys[:,ix] != 0)) * 1.0\n",
    "        Dn = sum((y2label_boys > 0) & (x2_boys[:,ix] == 0)) * 1.0\n",
    "        Hn = sum((y2label_boys == 0) & (x2_boys[:,ix] == 0)) * 1.0\n",
    "\n",
    "        OR = (De/He)/(Dn/Hn)\n",
    "        OR_sterror = np.sqrt(1/De + 1/He + 1/Dn + 1/Hn)\n",
    "        OR_low, OR_high = np.exp(np.log(OR) - 1.96*OR_sterror), np.exp(np.log(OR) + 1.96*OR_sterror)\n",
    "\n",
    "        RR = (De/(De+He))/(Dn/(Dn+Hn))\n",
    "\n",
    "        md = x2_boys[ix_total_pos,:][:,ix].mean() - x2_boys[ix_total_neg,:][:,ix].mean()\n",
    "        se = np.sqrt(np.var(x2_boys[ix_total_pos,:][:,ix]) / len(x2_boys[ix_total_pos,:][:,ix]) + np.var(x2_boys[ix_total_neg,:][:,ix])/len(x2_boys[ix_total_neg,:][:,ix]))\n",
    "        lcl, ucl = md-2*se, md+2*se\n",
    "        z = md/se\n",
    "\n",
    "        pvalue = 2 * norm.cdf(-1*(np.abs(np.log(OR))/OR_sterror)) if bin_indicator else 2 * norm.cdf(-np.abs(z))\n",
    "        char_table.append([\n",
    "                h, ix_total.sum(), x2_boys[ix_total,:][:,ix].mean(), x2_boys[ix_total,:][:,ix].std(),\n",
    "                ix_total_pos.sum(), x2_boys[ix_total_pos,:][:,ix].mean() if not(bin_indicator) else 0, x2_boys[ix_total_pos,:][:,ix].std() if not(bin_indicator) else 0,\n",
    "                ix_total_neg.sum(), x2_boys[ix_total_neg,:][:,ix].mean() if not(bin_indicator) else 0,  x2_boys[ix_total_neg,:][:,ix].std() if not(bin_indicator) else 0,\n",
    "                OR if bin_indicator else 0, OR_low if bin_indicator else 0, OR_high if bin_indicator else 0,\n",
    "                RR if bin_indicator else 0, pvalue\n",
    "        ])\n",
    "\n",
    "ft_info = pd.DataFrame(char_table, columns=cols)\n",
    "ft_info.to_csv('../summary_statistics/cohort_boys_feature_summary_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the girls subset of the data and output relevant information for each feature that has at least 5 occurrences in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_girls, y2_girls, y2label_girls, mrns2_girls, ix_filter_girls, feature_headers2_girls, corr_headers_filtered_girls, corrs_matrix_filtered_girls, ix_corr_headers_girls = \\\n",
    "    train.prepare_data_for_analysis({}, {}, {}, {}, {},\n",
    "        x1, y1, y1label[:,label_ix['obese']], feature_headers, mrns,\n",
    "        agex_low, agex_high, months_from, months_to,\n",
    "        filterSTR=['Gender:1'], # only the girls data\n",
    "        variablesubset=[], # do not remove any features\n",
    "        do_impute=False, # do not impute values\n",
    "        do_normalize=False, # do not normalize the values\n",
    "        min_occur=5, # use only features with meaningful information\n",
    "        delay_print=False, # print out all information as it's available\n",
    "        lasso_selection=False # do not use LASSO feature selection\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_table = []\n",
    "cols = ['Variable', 'Total N', 'Total Average', 'Total Std Dev', 'Obese N', 'Obese Average', 'Obese Std Dev', 'Not Obese N', 'Not Obese Average', 'Not Obese Std Dev', 'Unadjusted Odds Ratio', 'Unadjusted OR Low', 'Unadjusted OR High', 'Relative Risk', 'p-value for OR']\n",
    "y2pos_ix = (y2label_girls > 0)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    for ix, h in enumerate(feature_headers2_girls):\n",
    "        bin_indicator = x2_girls[:,ix].max()==1 and x2_girls[:,ix].min()==0\n",
    "\n",
    "        ix_total = (x2_girls[:,ix] != 0)\n",
    "        ix_total_pos = (y2label_girls > 0) & (x2_girls[:,ix] != 0)\n",
    "        ix_total_neg = (y2label_girls == 0) & (x2_girls[:,ix] != 0)\n",
    "\n",
    "        De = sum((y2label_girls > 0) & (x2_girls[:,ix] != 0)) * 1.0\n",
    "        He = sum((y2label_girls == 0) & (x2_girls[:,ix] != 0)) * 1.0\n",
    "        Dn = sum((y2label_girls > 0) & (x2_girls[:,ix] == 0)) * 1.0\n",
    "        Hn = sum((y2label_girls == 0) & (x2_girls[:,ix] == 0)) * 1.0\n",
    "\n",
    "        OR = (De/He)/(Dn/Hn)\n",
    "        OR_sterror = np.sqrt(1/De + 1/He + 1/Dn + 1/Hn)\n",
    "        OR_low, OR_high = np.exp(np.log(OR) - 1.96*OR_sterror), np.exp(np.log(OR) + 1.96*OR_sterror)\n",
    "\n",
    "        RR = (De/(De+He))/(Dn/(Dn+Hn))\n",
    "\n",
    "        md = x2_girls[ix_total_pos,:][:,ix].mean() - x2_girls[ix_total_neg,:][:,ix].mean()\n",
    "        se = np.sqrt(np.var(x2_girls[ix_total_pos,:][:,ix]) / len(x2_girls[ix_total_pos,:][:,ix]) + np.var(x2_girls[ix_total_neg,:][:,ix])/len(x2_girls[ix_total_neg,:][:,ix]))\n",
    "        lcl, ucl = md-2*se, md+2*se\n",
    "        z = md/se\n",
    "\n",
    "        pvalue = 2 * norm.cdf(-1*(np.abs(np.log(OR))/OR_sterror)) if bin_indicator else 2 * norm.cdf(-np.abs(z))\n",
    "        char_table.append([\n",
    "                h, ix_total.sum(), x2_girls[ix_total,:][:,ix].mean(), x2_girls[ix_total,:][:,ix].std(),\n",
    "                ix_total_pos.sum(), x2_girls[ix_total_pos,:][:,ix].mean() if not(bin_indicator) else 0, x2_girls[ix_total_pos,:][:,ix].std() if not(bin_indicator) else 0,\n",
    "                ix_total_neg.sum(), x2_girls[ix_total_neg,:][:,ix].mean() if not(bin_indicator) else 0,  x2_girls[ix_total_neg,:][:,ix].std() if not(bin_indicator) else 0,\n",
    "                OR if bin_indicator else 0, OR_low if bin_indicator else 0, OR_high if bin_indicator else 0,\n",
    "                RR if bin_indicator else 0, pvalue\n",
    "        ])\n",
    "\n",
    "ft_info = pd.DataFrame(char_table, columns=cols)\n",
    "ft_info.to_csv('../summary_statistics/cohort_girls_feature_summary_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
